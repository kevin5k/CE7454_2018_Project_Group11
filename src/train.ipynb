{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "      adjust_learning_rate, save_checkpoint, clip_gradient\n",
    "\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "\n",
    "from data_loader.ships_loader import create_imdb, ships_dataset\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.argv = ['trainval_net.py', '--cuda']\n",
    "\n",
    "def parse_args():\n",
    "  \"\"\"\n",
    "  Parse input arguments\n",
    "  \"\"\"\n",
    "  parser = argparse.ArgumentParser(description='Train a Faster R-CNN network')\n",
    "\n",
    "  parser.add_argument('--start_epoch', dest='start_epoch',\n",
    "                      help='starting epoch',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--net', dest='net',\n",
    "                      help='vgg16',\n",
    "                      default='vgg16', type=str)\n",
    "  parser.add_argument('--epochs', dest='max_epochs',\n",
    "                      help='number of epochs to train',\n",
    "                      default=20, type=int)\n",
    "  parser.add_argument('--disp_interval', dest='disp_interval',\n",
    "                      help='number of iterations to display',\n",
    "                      default=100, type=int)\n",
    "  parser.add_argument('--checkpoint_interval', dest='checkpoint_interval',\n",
    "                      help='number of iterations to display',\n",
    "                      default=10000, type=int)\n",
    "  parser.add_argument('--nw', dest='num_workers',\n",
    "                      help='number of worker to load data',\n",
    "                      default=0, type=int)\n",
    "  parser.add_argument('--cuda', dest='cuda',\n",
    "                      help='whether use CUDA',\n",
    "                      action='store_true')\n",
    "  parser.add_argument('--bs', dest='batch_size',\n",
    "                      help='batch_size',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--cag', dest='class_agnostic',\n",
    "                      help='whether perform class_agnostic bbox regression',\n",
    "                      action='store_true')\n",
    "\n",
    "# config optimization\n",
    "  parser.add_argument('--o', dest='optimizer',\n",
    "                      help='training optimizer',\n",
    "                      default=\"sgd\", type=str)\n",
    "  parser.add_argument('--lr', dest='lr',\n",
    "                      help='starting learning rate',\n",
    "                      default=0.001, type=float)\n",
    "  parser.add_argument('--lr_decay_step', dest='lr_decay_step',\n",
    "                      help='step to do learning rate decay, unit is epoch',\n",
    "                      default=3, type=int)\n",
    "  parser.add_argument('--lr_decay_gamma', dest='lr_decay_gamma',\n",
    "                      help='learning rate decay ratio',\n",
    "                      default=0.1, type=float)\n",
    "\n",
    "# set training session\n",
    "  parser.add_argument('--s', dest='session',\n",
    "                      help='training session',\n",
    "                      default=1, type=int)\n",
    "\n",
    "# resume trained model\n",
    "  parser.add_argument('--r', dest='resume',\n",
    "                      help='resume checkpoint or not',\n",
    "                      default=False, type=bool)\n",
    "  parser.add_argument('--checksession', dest='checksession',\n",
    "                      help='checksession to load model',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--checkepoch', dest='checkepoch',\n",
    "                      help='checkepoch to load model',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--checkpoint', dest='checkpoint',\n",
    "                      help='checkpoint to load model',\n",
    "                      default=0, type=int)\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called with args:\n",
      "Namespace(batch_size=1, checkepoch=1, checkpoint=0, checkpoint_interval=10000, checksession=1, class_agnostic=False, cuda=True, disp_interval=100, lr=0.001, lr_decay_gamma=0.1, lr_decay_step=3, max_epochs=20, net='vgg16', num_workers=0, optimizer='sgd', resume=False, session=1, start_epoch=1)\n",
      "Using config:\n",
      "{'ANCHOR_RATIOS': [0.5, 1, 2],\n",
      " 'ANCHOR_SCALES': [8, 16, 32],\n",
      " 'CROP_RESIZE_WITH_MAX_POOL': False,\n",
      " 'CUDA': True,\n",
      " 'DATA_DIR': '/root/workspace/project/src/data',\n",
      " 'DEDUP_BOXES': 0.0625,\n",
      " 'EPS': 1e-14,\n",
      " 'EXP_DIR': 'vgg16',\n",
      " 'FEAT_STRIDE': [16],\n",
      " 'GPU_ID': 0,\n",
      " 'MATLAB': 'matlab',\n",
      " 'MAX_NUM_GT_BOXES': 20,\n",
      " 'MOBILENET': {'DEPTH_MULTIPLIER': 1.0,\n",
      "               'FIXED_LAYERS': 5,\n",
      "               'REGU_DEPTH': False,\n",
      "               'WEIGHT_DECAY': 4e-05},\n",
      " 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),\n",
      " 'POOLING_MODE': 'align',\n",
      " 'POOLING_SIZE': 7,\n",
      " 'RESNET': {'FIXED_BLOCKS': 1, 'MAX_POOL': False},\n",
      " 'RNG_SEED': 3,\n",
      " 'ROOT_DIR': '/root/workspace/project/src',\n",
      " 'TEST': {'BBOX_REG': True,\n",
      "          'HAS_RPN': True,\n",
      "          'MAX_SIZE': 1000,\n",
      "          'MODE': 'nms',\n",
      "          'NMS': 0.3,\n",
      "          'PROPOSAL_METHOD': 'gt',\n",
      "          'RPN_MIN_SIZE': 16,\n",
      "          'RPN_NMS_THRESH': 0.7,\n",
      "          'RPN_POST_NMS_TOP_N': 300,\n",
      "          'RPN_PRE_NMS_TOP_N': 6000,\n",
      "          'RPN_TOP_N': 5000,\n",
      "          'SCALES': [600],\n",
      "          'SVM': False},\n",
      " 'TRAIN': {'ASPECT_GROUPING': False,\n",
      "           'BATCH_SIZE': 256,\n",
      "           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],\n",
      "           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],\n",
      "           'BBOX_NORMALIZE_TARGETS': True,\n",
      "           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,\n",
      "           'BBOX_REG': True,\n",
      "           'BBOX_THRESH': 0.5,\n",
      "           'BG_THRESH_HI': 0.5,\n",
      "           'BG_THRESH_LO': 0.0,\n",
      "           'BIAS_DECAY': False,\n",
      "           'BN_TRAIN': False,\n",
      "           'DISPLAY': 10,\n",
      "           'DOUBLE_BIAS': True,\n",
      "           'FG_FRACTION': 0.25,\n",
      "           'FG_THRESH': 0.5,\n",
      "           'GAMMA': 0.1,\n",
      "           'HAS_RPN': True,\n",
      "           'IMS_PER_BATCH': 1,\n",
      "           'LEARNING_RATE': 0.01,\n",
      "           'MAX_SIZE': 1000,\n",
      "           'MOMENTUM': 0.9,\n",
      "           'PROPOSAL_METHOD': 'gt',\n",
      "           'RPN_BATCHSIZE': 256,\n",
      "           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],\n",
      "           'RPN_CLOBBER_POSITIVES': False,\n",
      "           'RPN_FG_FRACTION': 0.5,\n",
      "           'RPN_MIN_SIZE': 8,\n",
      "           'RPN_NEGATIVE_OVERLAP': 0.3,\n",
      "           'RPN_NMS_THRESH': 0.7,\n",
      "           'RPN_POSITIVE_OVERLAP': 0.7,\n",
      "           'RPN_POSITIVE_WEIGHT': -1.0,\n",
      "           'RPN_POST_NMS_TOP_N': 2000,\n",
      "           'RPN_PRE_NMS_TOP_N': 12000,\n",
      "           'SCALES': [600],\n",
      "           'SNAPSHOT_ITERS': 5000,\n",
      "           'SNAPSHOT_KEPT': 3,\n",
      "           'SNAPSHOT_PREFIX': 'res101_faster_rcnn',\n",
      "           'STEPSIZE': [30000],\n",
      "           'SUMMARY_INTERVAL': 180,\n",
      "           'TRIM_HEIGHT': 600,\n",
      "           'TRIM_WIDTH': 600,\n",
      "           'TRUNCATED': False,\n",
      "           'USE_ALL_GT': True,\n",
      "           'USE_FLIPPED': True,\n",
      "           'USE_GT': False,\n",
      "           'WEIGHT_DECAY': 0.0005},\n",
      " 'USE_GPU_NMS': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    args.cuda = True\n",
    "\n",
    "    print('Called with args:')\n",
    "    print(args)\n",
    "    args.cfg_file = \"cfgs/{}.yml\".format(args.net)\n",
    "    args.set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20']\n",
    "\n",
    "    if args.cfg_file is not None:\n",
    "        cfg_from_file(args.cfg_file)\n",
    "    if args.set_cfgs is not None:\n",
    "        cfg_from_list(args.set_cfgs)\n",
    "\n",
    "    print('Using config:')\n",
    "    pprint.pprint(cfg)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "    np.random.seed(cfg.RNG_SEED)\n",
    "\n",
    "    #torch.backends.cudnn.benchmark = True\n",
    "    if torch.cuda.is_available() and not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "    # train set\n",
    "    # -- Note: Use validation set and disable the flipped to enable faster loading.\n",
    "    # cfg.TRAIN.USE_FLIPPED = True\n",
    "    cfg.USE_GPU_NMS = args.cuda\n",
    "\n",
    "    models_dir = \"../models/\" + args.net\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "\n",
    "    imdb = create_imdb(\"../dataset/bbox_dictionary.csv\", \"../dataset/train\")\n",
    "    dataset = ships_dataset(imdb)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=1)\n",
    "    train_size = len(imdb)\n",
    "    # initilize the tensor holder here.\n",
    "    im_data = torch.FloatTensor(1)\n",
    "    im_info = torch.FloatTensor(1)\n",
    "    num_boxes = torch.LongTensor(1)\n",
    "    gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "    # ship to cuda\n",
    "    if args.cuda:\n",
    "        im_data = im_data.cuda()\n",
    "        im_info = im_info.cuda()\n",
    "        num_boxes = num_boxes.cuda()\n",
    "        gt_boxes = gt_boxes.cuda()\n",
    "\n",
    "    if args.cuda:\n",
    "        cfg.CUDA = True\n",
    "\n",
    "    ships_classes = np.asarray(['__background__', 'ships'])\n",
    "\n",
    "    # initilize the network here.\n",
    "    fasterRCNN = vgg16(ships_classes)\n",
    "\n",
    "    fasterRCNN.create_architecture()\n",
    "\n",
    "    lr = cfg.TRAIN.LEARNING_RATE\n",
    "    lr = args.lr\n",
    "    #tr_momentum = cfg.TRAIN.MOMENTUM\n",
    "    #tr_momentum = args.momentum\n",
    "\n",
    "    params = []\n",
    "    for key, value in dict(fasterRCNN.named_parameters()).items():\n",
    "        if value.requires_grad:\n",
    "            if 'bias' in key:\n",
    "                params += [{'params':[value],'lr':lr*(cfg.TRAIN.DOUBLE_BIAS + 1), \\\n",
    "                        'weight_decay': cfg.TRAIN.BIAS_DECAY and cfg.TRAIN.WEIGHT_DECAY or 0}]\n",
    "            else:\n",
    "                params += [{'params':[value],'lr':lr, 'weight_decay': cfg.TRAIN.WEIGHT_DECAY}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.optimizer == \"adam\":\n",
    "        lr = lr * 0.1\n",
    "        optimizer = torch.optim.Adam(params)\n",
    "\n",
    "    elif args.optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(params, momentum=cfg.TRAIN.MOMENTUM)\n",
    "\n",
    "    if args.cuda:\n",
    "        fasterRCNN.cuda()\n",
    "\n",
    "    if args.resume:\n",
    "        load_name = os.path.join(models_dir,\n",
    "          'faster_rcnn_{}_{}_{}.pth'.format(args.checksession, args.checkepoch, args.checkpoint))\n",
    "        print(\"loading checkpoint %s\" % (load_name))\n",
    "        checkpoint = torch.load(load_name)\n",
    "        args.session = checkpoint['session']\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        fasterRCNN.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        if 'pooling_mode' in checkpoint.keys():\n",
    "            cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "        print(\"loaded checkpoint %s\" % (load_name))\n",
    "\n",
    "    iters_per_epoch = int(train_size / args.batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[session 1][epoch  1][iter    0/29070] loss: 2.4922, lr: 1.00e-03\n",
      "\t\t\tfg/bg=(3/253), time cost: 0.226786\n",
      "\t\t\trpn_cls: 0.8463, rpn_box: 0.8374, rcnn_cls: 0.8048, rcnn_box 0.0037\n",
      "[session 1][epoch  1][iter  100/29070] loss: 0.8083, lr: 1.00e-03\n",
      "\t\t\tfg/bg=(6/250), time cost: 20.152362\n",
      "\t\t\trpn_cls: 0.1360, rpn_box: 0.0053, rcnn_cls: 0.1927, rcnn_box 0.0630\n",
      "[session 1][epoch  1][iter  200/29070] loss: 0.5483, lr: 1.00e-03\n",
      "\t\t\tfg/bg=(1/255), time cost: 21.237140\n",
      "\t\t\trpn_cls: 0.2005, rpn_box: 0.1540, rcnn_cls: 0.0466, rcnn_box 0.0001\n",
      "[session 1][epoch  1][iter  300/29070] loss: 0.5627, lr: 1.00e-03\n",
      "\t\t\tfg/bg=(3/253), time cost: 21.394147\n",
      "\t\t\trpn_cls: 0.5954, rpn_box: 0.8446, rcnn_cls: 0.0721, rcnn_box 0.0002\n",
      "[session 1][epoch  1][iter  400/29070] loss: 0.5162, lr: 1.00e-03\n",
      "\t\t\tfg/bg=(1/255), time cost: 20.699475\n",
      "\t\t\trpn_cls: 0.3217, rpn_box: 0.6624, rcnn_cls: 0.0295, rcnn_box 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-964fbcdd95db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mclip_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasterRCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/project/src/lib/model/utils/net_utils.py\u001b[0m in \u001b[0;36mclip_gradient\u001b[0;34m(model, clip_norm)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mmodulenorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mtotalnorm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodulenorm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtotalnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    for epoch in range(args.start_epoch, args.max_epochs + 1):\n",
    "        # setting to train mode\n",
    "        fasterRCNN.train()\n",
    "        loss_temp = 0\n",
    "        start = time.time()\n",
    "\n",
    "        if epoch % (args.lr_decay_step + 1) == 0:\n",
    "            adjust_learning_rate(optimizer, args.lr_decay_gamma)\n",
    "            lr *= args.lr_decay_gamma\n",
    "            \n",
    "        data_iter = iter(dataloader)\n",
    "            \n",
    "        for step in range(iters_per_epoch):\n",
    "            data = next(data_iter)\n",
    "            im_data.data.resize_(data[0].size()).copy_(data[0])\n",
    "            im_info.data.resize_(data[1].size()).copy_(data[1])\n",
    "            gt_boxes.data.resize_(data[2].size()).copy_(data[2])\n",
    "            num_boxes.data.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "            fasterRCNN.zero_grad()\n",
    "            rois, cls_prob, bbox_pred, \\\n",
    "            rpn_loss_cls, rpn_loss_box, \\\n",
    "            RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "            rois_label = fasterRCNN(im_data, im_info, gt_boxes, num_boxes)\n",
    "\n",
    "            loss = rpn_loss_cls.mean() + rpn_loss_box.mean() \\\n",
    "               + RCNN_loss_cls.mean() + RCNN_loss_bbox.mean()\n",
    "            loss_temp += loss.item()\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            clip_gradient(fasterRCNN, 10.)\n",
    "            optimizer.step()\n",
    "\n",
    "            if step % args.disp_interval == 0:\n",
    "                end = time.time()\n",
    "                if step > 0:\n",
    "                    loss_temp /= (args.disp_interval + 1)\n",
    "\n",
    "\n",
    "                loss_rpn_cls = rpn_loss_cls.item()\n",
    "                loss_rpn_box = rpn_loss_box.item()\n",
    "                loss_rcnn_cls = RCNN_loss_cls.item()\n",
    "                loss_rcnn_box = RCNN_loss_bbox.item()\n",
    "                fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "                bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "\n",
    "                print(\"[session %d][epoch %2d][iter %4d/%4d] loss: %.4f, lr: %.2e\" \\\n",
    "                                        % (args.session, epoch, step, iters_per_epoch, loss_temp, lr))\n",
    "                print(\"\\t\\t\\tfg/bg=(%d/%d), time cost: %f\" % (fg_cnt, bg_cnt, end-start))\n",
    "                print(\"\\t\\t\\trpn_cls: %.4f, rpn_box: %.4f, rcnn_cls: %.4f, rcnn_box %.4f\" \\\n",
    "                      % (loss_rpn_cls, loss_rpn_box, loss_rcnn_cls, loss_rcnn_box))\n",
    "\n",
    "                loss_temp = 0\n",
    "                start = time.time()\n",
    "        save_name = os.path.join(models_dir, 'faster_rcnn_{}_{}_{}.pth'.format(args.session, epoch, step))\n",
    "        save_checkpoint({\n",
    "            'session': args.session,\n",
    "            'epoch': epoch,\n",
    "            'model': fasterRCNN.module.state_dict() if args.mGPUs else fasterRCNN.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'pooling_mode': cfg.POOLING_MODE,\n",
    "            'class_agnostic': args.class_agnostic,\n",
    "        }, save_name)\n",
    "        print('save model: {}'.format(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
